{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating IODP site data (Excel files for KML conversion)\n",
    "\n",
    "Proposed sites, scheduled expeditions, and recently completed expeditions from https://www.iodp.org/resources/maps-and-kml-tools\n",
    "\n",
    "---\n",
    "\n",
    "There are 3 KML files on the IODP Maps & Resources webpage that need to be updated a few times a year:\n",
    "- Proposed sites\n",
    "- Scheduled expeditions\n",
    "- Recently completed expeditions\n",
    "\n",
    "These files are for IODP holes that haven't yet made it into the Drilled Holes KML, which contains comprehensive drilling data from the ship operator. Before our office gets data from the ship operators, we can track the status of the holes throughout the proposal and expedition stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# URLs with information to update Excel files\n",
    "url1 = \"https://www.iodp.org/proposals/active-proposals\"\n",
    "url2 = \"https://ssdb.iodp.org/SSDBupload/site_information.php?propID=ALL\"\n",
    "url3 = \"https://www.iodp.org/expeditions/expeditions-schedule\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Sites Excel file\n",
    "\n",
    "ProposedSites_MonthYear.xlsx contains the following data:  \n",
    "**Site Name / Name / Latitude / Longitude / Lead Proponent / Stage / Platform / Icon / IconScale / LabelScale / AppendData / IconColor / Description**\n",
    "\n",
    "The data from the old file needs to be updated (add new proposed sites, remove de-activated or scheduled proposed sites).\n",
    "\n",
    "First, we will add rows to the Excel file by pulling information from the [Active Proposals page](https://www.iodp.org/proposals/active-proposals) and [SIF site list](https://ssdb.iodp.org/SSDBupload/site_information.php?propID=ALL).  \n",
    "From the Active Proposals page, we need the Proposal Number, Short Title, Lead Proponent, Platform, and Stage.  \n",
    "From the SIF site list, we need the Site Name, Proposal ID, Latitude, and Longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Proposal Number</th>\n",
       "      <th>Short Title</th>\n",
       "      <th>Lead Proponent</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>P932</td>\n",
       "      <td>Hellenic Arc Volcanic Field</td>\n",
       "      <td>Druitt</td>\n",
       "      <td>JOIDES Resolution</td>\n",
       "      <td>SEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>P933</td>\n",
       "      <td>NW African Continental Margin Climate</td>\n",
       "      <td>Bickert</td>\n",
       "      <td>JOIDES Resolution</td>\n",
       "      <td>SEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>P934</td>\n",
       "      <td>Arctic Atlantic Gateway Climate</td>\n",
       "      <td>Geissler</td>\n",
       "      <td>JOIDES Resolution</td>\n",
       "      <td>SEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>P935</td>\n",
       "      <td>Arctic Fluid Flow Systems</td>\n",
       "      <td>Bünz</td>\n",
       "      <td>JOIDES Resolution</td>\n",
       "      <td>SEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>P937</td>\n",
       "      <td>Deepening Hole U1309D</td>\n",
       "      <td>McCaig</td>\n",
       "      <td>JOIDES Resolution</td>\n",
       "      <td>SEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>P939</td>\n",
       "      <td>Tohoku Petit-Spot Magmatism</td>\n",
       "      <td>Yamaguchi</td>\n",
       "      <td>Chikyu</td>\n",
       "      <td>SEP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Proposal Number                            Short Title Lead Proponent  \\\n",
       "84            P932            Hellenic Arc Volcanic Field         Druitt   \n",
       "85            P933  NW African Continental Margin Climate        Bickert   \n",
       "86            P934        Arctic Atlantic Gateway Climate       Geissler   \n",
       "87            P935              Arctic Fluid Flow Systems           Bünz   \n",
       "88            P937                  Deepening Hole U1309D         McCaig   \n",
       "89            P939            Tohoku Petit-Spot Magmatism      Yamaguchi   \n",
       "\n",
       "             Platform Stage  \n",
       "84  JOIDES Resolution   SEP  \n",
       "85  JOIDES Resolution   SEP  \n",
       "86  JOIDES Resolution   SEP  \n",
       "87  JOIDES Resolution   SEP  \n",
       "88  JOIDES Resolution   SEP  \n",
       "89             Chikyu   SEP  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in existing Excel file to find last proposal number and create new Excel file\n",
    "old_excel_file = 'ProposedSites_May2018.xlsx'\n",
    "new_excel_file = 'ProposedSites_September2018.xlsx'\n",
    "\n",
    "# copy contents of old Excel file to new one for updating\n",
    "import shutil\n",
    "shutil.copy(old_excel_file, new_excel_file)\n",
    "\n",
    "# get last proposal number from old Excel file\n",
    "df = pd.read_excel(new_excel_file)\n",
    "lastprop = df['Name'].iloc[-1]\n",
    "\n",
    "# read Active Proposals page html into string\n",
    "try:\n",
    "    page = urllib.request.urlopen(url1).read()\n",
    "except:\n",
    "    print(\"Cannot read url\")\n",
    "\n",
    "# read into beautifulsoup for parsing\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "#proposals = soup.tbody\n",
    "\n",
    "# get information for new proposals to append to Excel file\n",
    "table = soup.find(\"table\", attrs={\"class\":\"tablesorter\"})\n",
    "headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "table_body = table.find('tbody')\n",
    "\n",
    "data = []\n",
    "rows = table_body.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols if ele])\n",
    "#print(data)\n",
    "\n",
    "# create pandas dataframe and extract relevant fields\n",
    "propdf = pd.DataFrame(data, columns=headings)\n",
    "del propdf['Type']\n",
    "del propdf['Ocean Basin']\n",
    "\n",
    "# save copy of dataframe for later use\n",
    "propdfsave = propdf.copy()\n",
    "\n",
    "# remove all rows above last proposal number already in Excel file\n",
    "lastind = propdf[propdf['Proposal Number'] == str(lastprop)].index[0]\n",
    "propdf = propdf.iloc[lastind+1::]\n",
    "\n",
    "# add P to beginning of proposal number column to match SIF list\n",
    "propdf['Proposal Number'] = 'P'+propdf['Proposal Number']\n",
    "\n",
    "# get list of proposal numbers to add to Excel file\n",
    "proplist = propdf['Proposal Number'].tolist()\n",
    "\n",
    "propdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the new proposals with sites that need to be added to the Excel file.\n",
    "\n",
    "Next, we'll get the sites associated with each proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site Name</th>\n",
       "      <th>Name</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Lead Proponent</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Icon</th>\n",
       "      <th>IconScale</th>\n",
       "      <th>LabelScale</th>\n",
       "      <th>AppendData</th>\n",
       "      <th>IconColor</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSK-01A</td>\n",
       "      <td>932</td>\n",
       "      <td>36.7293</td>\n",
       "      <td>25.6482</td>\n",
       "      <td>Druitt</td>\n",
       "      <td>SEP</td>\n",
       "      <td>JR</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>fuchsia</td>\n",
       "      <td>Hellenic Arc Volcanic Field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSK-02A</td>\n",
       "      <td>932</td>\n",
       "      <td>36.7438</td>\n",
       "      <td>25.7146</td>\n",
       "      <td>Druitt</td>\n",
       "      <td>SEP</td>\n",
       "      <td>JR</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>fuchsia</td>\n",
       "      <td>Hellenic Arc Volcanic Field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSK-03A</td>\n",
       "      <td>932</td>\n",
       "      <td>36.5549</td>\n",
       "      <td>25.4398</td>\n",
       "      <td>Druitt</td>\n",
       "      <td>SEP</td>\n",
       "      <td>JR</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>fuchsia</td>\n",
       "      <td>Hellenic Arc Volcanic Field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSK-04A</td>\n",
       "      <td>932</td>\n",
       "      <td>36.5728</td>\n",
       "      <td>25.4092</td>\n",
       "      <td>Druitt</td>\n",
       "      <td>SEP</td>\n",
       "      <td>JR</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>fuchsia</td>\n",
       "      <td>Hellenic Arc Volcanic Field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSK-05A</td>\n",
       "      <td>932</td>\n",
       "      <td>36.4355</td>\n",
       "      <td>25.3805</td>\n",
       "      <td>Druitt</td>\n",
       "      <td>SEP</td>\n",
       "      <td>JR</td>\n",
       "      <td>208</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>fuchsia</td>\n",
       "      <td>Hellenic Arc Volcanic Field</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Site Name Name Latitude Longitude Lead Proponent Stage Platform Icon  \\\n",
       "0   CSK-01A  932  36.7293   25.6482         Druitt   SEP       JR  208   \n",
       "1   CSK-02A  932  36.7438   25.7146         Druitt   SEP       JR  208   \n",
       "2   CSK-03A  932  36.5549   25.4398         Druitt   SEP       JR  208   \n",
       "3   CSK-04A  932  36.5728   25.4092         Druitt   SEP       JR  208   \n",
       "4   CSK-05A  932  36.4355   25.3805         Druitt   SEP       JR  208   \n",
       "\n",
       "  IconScale LabelScale AppendData IconColor                  Description  \n",
       "0         3          3        Yes   fuchsia  Hellenic Arc Volcanic Field  \n",
       "1         3          3        Yes   fuchsia  Hellenic Arc Volcanic Field  \n",
       "2         3          3        Yes   fuchsia  Hellenic Arc Volcanic Field  \n",
       "3         3          3        Yes   fuchsia  Hellenic Arc Volcanic Field  \n",
       "4         3          3        Yes   fuchsia  Hellenic Arc Volcanic Field  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read SIF site list html into string\n",
    "try:\n",
    "    page = urllib.request.urlopen(url2).read()\n",
    "except:\n",
    "    print(\"Cannot read url\")\n",
    "\n",
    "# read into beautifulsoup for parsing\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "table_body = soup.table\n",
    "\n",
    "data = []\n",
    "rows = table_body.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols if ele])\n",
    "#print(data)\n",
    "\n",
    "# create pandas dataframe for SIF site list\n",
    "sitedf = pd.DataFrame(data)\n",
    "sitedf.columns = ['Site Name','Proposal Number','Latitude','Longitude']\n",
    "\n",
    "# search through dataframe for rows that match proposal list\n",
    "#for ii in range(len(proplist)):\n",
    "#    print(sitedf[sitedf[1] == proplist[ii]], propdf[propdf['Proposal Number'] == proplist[ii]])\n",
    "\n",
    "# merge proposal list and site list\n",
    "newdf = propdf.merge(sitedf, on='Proposal Number')\n",
    "\n",
    "# add other columns and reorganize to match Excel file\n",
    "newdf['Icon']='208'\n",
    "newdf['IconScale']='3'\n",
    "newdf['LabelScale']='3'\n",
    "newdf['AppendData']='Yes'\n",
    "newdf['IconColor']='fuchsia'\n",
    "\n",
    "newdf = newdf.rename(index=str, columns={\"Proposal Number\":\"Name\", \"Short Title\":\"Description\"})\n",
    "\n",
    "newdf = newdf[['Site Name', 'Name', 'Latitude', 'Longitude', 'Lead Proponent', 'Stage', \\\n",
    "               'Platform', 'Icon', 'IconScale', 'LabelScale', 'AppendData', 'IconColor', 'Description']]\n",
    "\n",
    "# rename fields within a column to be consistent with previous content\n",
    "newdf.loc[newdf.Platform == 'JOIDES Resolution', 'Platform'] = \"JR\"\n",
    "newdf.loc[newdf.Platform == 'Mission Specific Platform', 'Platform'] = \"MSP\"\n",
    "\n",
    "# remove 'P' from Proposal Name to be consistent with previous content\n",
    "newdf['Name'] = newdf['Name'].str[1:]\n",
    "\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all the sites for the new proposals that will be added to the Excel file.\n",
    "\n",
    "Next, we can update and save our results to the Excel file.\n",
    "\n",
    "Helpful XlsxWriter documentation can be found here: https://xlsxwriter.readthedocs.io/working_with_pandas.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export dataframe and append to Excel file\n",
    "writer = pd.ExcelWriter(new_excel_file, engine='xlsxwriter')\n",
    "df.to_excel(writer, index=False)\n",
    "newdf.to_excel(writer, startrow=len(df)+1, index=False, header=False)\n",
    "\n",
    "# get xlsxwriter objects from the dataframe writer object\n",
    "#workbook = writer.book\n",
    "#worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "# add some cell formats\n",
    "#cell_format = workbook.add_format()\n",
    "#cell_format.set_align('left')\n",
    "#worksheet.set_column('A:D', 10)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Proposed Sites Excel file has been updated with the new proposed sites.  \n",
    "\n",
    "Next, we'll remove the sites for proposals that have been deactivated.  \n",
    "\n",
    "**Note: This part will have to be updated manually, as the number of de-activated proposals will vary each time we run the code. A list of de-activated proposals will need to be obtained after each SEP meeting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in edited Excel file\n",
    "df = pd.read_excel(new_excel_file)\n",
    "\n",
    "# make sure values in 'Name' column are strings\n",
    "df['Name'] = df['Name'].astype(str)\n",
    "\n",
    "# get index values corresponding to proposals that have been de-activated\n",
    "# !!! must update proposal IDs of de-activated proposals here !!!\n",
    "idx = df.index[df['Name'] == '914'].tolist()\n",
    "idx.extend(df.index[df['Name'] == '922'].tolist())\n",
    "idx.extend(df.index[df['Name'] == '930'].tolist())\n",
    "\n",
    "# drop rows from dataframe\n",
    "newdf = df.drop(df.index[idx])\n",
    "\n",
    "# replace dataframe in Excel file\n",
    "writer = pd.ExcelWriter(new_excel_file, engine='xlsxwriter')\n",
    "newdf.to_excel(writer, index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the proposal has been scheduled as an expedition, we'll remove the relevant sites from the Proposed Sites Excel file and put them into the Scheduled Expeditions Excel file. We can list out the Expeditions here as well, so we know the sites associated with the proposals should show up in the other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These proposals have been scheduled as expeditions:  ['716' '834' '846' '853' '859' '864' '890']\n",
      "Make sure they are in the Scheduled Expeditions Excel file.\n"
     ]
    }
   ],
   "source": [
    "# read in updated proposed sites Excel file\n",
    "df = pd.read_excel(new_excel_file)\n",
    "\n",
    "# search Active Proposals webpage for 'Exp' in Stage column and get corresponding proposal number\n",
    "expdf = propdfsave[propdfsave['Stage'].str.match(\"Exp\")]\n",
    "expdf = expdf.rename(index=str, columns={\"Proposal Number\":\"Name\"})\n",
    "\n",
    "# find the proposal-expeditions that show up in the Excel file (if there are any)\n",
    "deldf = pd.merge(expdf, df, on='Name')\n",
    "\n",
    "# remove proposal-expeditions from Excel file\n",
    "dellist = deldf.Name.unique().tolist()\n",
    "\n",
    "idx = []\n",
    "for i in dellist:\n",
    "    idx.extend(df.index[df['Name'] == i].tolist())\n",
    "\n",
    "# drop rows from dataframe\n",
    "newdf = df.drop(df.index[idx])\n",
    "\n",
    "# replace dataframe in Excel file\n",
    "writer = pd.ExcelWriter(new_excel_file, engine='xlsxwriter')\n",
    "newdf.to_excel(writer, index=False)\n",
    "writer.save()\n",
    "\n",
    "# output list of proposals that have been scheduled as expeditions\n",
    "# because they may need to go into Scheduled Expeditions Excel file\n",
    "print('These proposals have been scheduled as expeditions: ',deldf.Name.unique())\n",
    "print('Make sure they are in the Scheduled Expeditions Excel file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scheduled Expeditions Excel file\n",
    "\n",
    "The top table on the [Expeditions Schedule page](https://www.iodp.org/expeditions/expeditions-schedule) shows proposals that have been scheduled as expeditions. The proposed drilling sites for these expeditions should be listed in the Scheduled Expeditions Excel file.\n",
    "\n",
    "ScheduledExpeditions_MonthYear.xlsx contains the following data:  \n",
    "**Site Name / Latitude / Longitude / Name / Schedule / Icon / IconColor / IconScale / LabelScale / AppendDataColumnsToDescription / Description / Original Proposal / Drilling Platform / Co-chief Scientists / web info **\n",
    "\n",
    "We'll need to find out which expeditions should be removed from the Scheduled Expeditions Excel file (ones that are no longer in the table on the webpage) and which expeditions should be added to the Scheduled Expeditions Excel file (ones that have progressed from Proposed Sites to Scheduled Expeditions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These expeditions should be removed from the Excel file:  ['376']\n",
      "Make sure they are in the Recently Completed Expeditions Excel file.\n",
      "\n",
      "These expeditions should be added to the Excel file:  ['387', '390', '391', '388', '389', '392', '393']\n"
     ]
    }
   ],
   "source": [
    "# get expeditions listed in the Excel file\n",
    "old_excel_file = 'ScheduledExpeditions_May2018.xlsx'\n",
    "new_excel_file = 'ScheduledExpeditions_September2018.xlsx'\n",
    "\n",
    "# copy contents of old Excel file to new one for updating\n",
    "shutil.copy(old_excel_file, new_excel_file)\n",
    "\n",
    "# read in old Excel file\n",
    "df = pd.read_excel(old_excel_file)\n",
    "\n",
    "# remove 'Exp ' from Name column in Excel file\n",
    "#df['Name'] = df['Name'].str[4:]\n",
    "\n",
    "# get list of expeditions in the Excel file\n",
    "xlexplist = df['Name'].str[4:].unique().tolist()\n",
    "\n",
    "# read Expeditions Schedule page html into string\n",
    "try:\n",
    "    page = urllib.request.urlopen(url3).read()\n",
    "except:\n",
    "    print(\"Cannot read url\")\n",
    "\n",
    "# read into beautifulsoup for parsing\n",
    "soup = BeautifulSoup(page,'html.parser')\n",
    "#proposals = soup.tbody\n",
    "\n",
    "# get information for scheduled expeditions\n",
    "table = soup.find(\"table\", attrs={\"id\":\"scheduledExpeditionsTable\"})\n",
    "headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "table_body = table.find('tbody')\n",
    "\n",
    "data = []\n",
    "rows = table_body.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = row.find_all('td')\n",
    "    cols = [ele.text.strip() for ele in cols]\n",
    "    data.append([ele for ele in cols if ele])\n",
    "#print(data)\n",
    "\n",
    "# create pandas dataframe\n",
    "expdf = pd.DataFrame(data, columns=headings).dropna()\n",
    "expdf = expdf.rename(index=str, columns={\"#\":\"Name\"})\n",
    "\n",
    "# get list of scheduled expeditions from the webpage\n",
    "siteexplist = expdf.Name.tolist()\n",
    "\n",
    "# get difference between lists of expeditions on the webpage and in the Excel file\n",
    "\n",
    "# expeditions that are in the Excel file but not on the webpage (remove from Excel)\n",
    "rmfromxl = list(set(xlexplist) - set(siteexplist))\n",
    "\n",
    "# expeditions that are on the webpage but not in the Excel file (add to Excel)\n",
    "addtoxl = list(set(siteexplist) - set(xlexplist))\n",
    "\n",
    "print('These expeditions should be removed from the Excel file: ',rmfromxl)\n",
    "print('Make sure they are in the Recently Completed Expeditions Excel file.')\n",
    "print('')\n",
    "print('These expeditions should be added to the Excel file: ',addtoxl)\n",
    "#print('The expeditions should correspond to the following proposals: ',deldf.Name.unique())\n",
    "\n",
    "#expdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know which expeditions and respective sites should be included in the Excel file, we need to get the data formatted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the proposals that have been scheduled as expeditions (removed from Proposed Sites Excel file)\n",
    "# to the Scheduled Expeditions Excel file\n",
    "\n",
    "# table of proposals and corresponding expeditions that were recently scheduled (from Proposed Sites Excel file)\n",
    "prop2expdf = deldf[['Name','Stage_x']].drop_duplicates()\n",
    "prop2expdf = prop2expdf.rename(index=str, columns={\"Name\":\"Proposal Number\", \"Stage_x\":\"Expedition\"})\n",
    "prop2expdf['Expedition'] = prop2expdf['Expedition'].str[3:]\n",
    "\n",
    "# note: the expeditions listed in prop2expdf may not match the above lists if multiple expeditions are scheduled\n",
    "# from one proposal (e.g., Proposal 853 and Expeditions 390/393)\n",
    "\n",
    "# we will use the list of expeditions in 'addtoxl' and find the corresponding proposed sites to add to the\n",
    "# Scheduled Expeditions Excel file\n",
    "\n",
    "# add blank columns to relevant proposed sites dataframe\n",
    "deldf[\"Schedule\"] = np.nan\n",
    "deldf[\"web info\"] = np.nan\n",
    "\n",
    "# copy relevant columns from proposed sites into new dataframe\n",
    "newdf = deldf[['Site Name','Latitude','Longitude','Stage_x','Schedule','Icon','IconColor','IconScale','LabelScale',\\\n",
    "               'AppendDataColumnsToDescription','Description','Name','Platform_x','Lead Proponent_x','web info']]\n",
    "\n",
    "# rename headers to match Scheduled Expeditions Excel file\n",
    "newdf = newdf.rename(index=str, columns={\"Name\":\"Original Proposal\", \"Platform_x\":\"Drilling Platform\", \\\n",
    "                                         \"Stage_x\":\"Name\", \"Lead Proponent_x\":\"Co-chief Scientists\"})\n",
    "\n",
    "# update miscellaneous column data and formatting\n",
    "newdf.loc[newdf.IconColor == 'fuchsia', 'IconColor'] = \"cyan\"\n",
    "newdf['Name'] = 'Exp '+newdf['Name'].str[3:]\n",
    "df['Name'] ='Exp '+df['Name']\n",
    "\n",
    "#newdf\n",
    "\n",
    "# export dataframe and append to Scheduled Expeditions Excel file\n",
    "writer = pd.ExcelWriter(new_excel_file, engine='xlsxwriter')\n",
    "df.to_excel(writer, index=False)\n",
    "newdf.to_excel(writer, startrow=len(df)+1, index=False, header=False)\n",
    "\n",
    "writer.save()\n",
    "\n",
    "# note: check Expedition name column ... make sure 'Exp Exp ###' doesn't show up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the table that will be appended to the Scheduled Expeditions Excel file.\n",
    "\n",
    "The 'Schedule', 'Original Proposal', 'Co-chief Scientists', and 'web info' columns will need to be updated or filled in manually. Go to the [Expeditions Schedule page](https://www.iodp.org/expeditions/expeditions-schedule) and use the dates and links to JRSO's expedition sites to find the appropriate information to enter in the Excel file.\n",
    "\n",
    "Remember to manually cut and paste the relevant rows of any recently completed expeditions mentioned above from the Scheduled Expeditions to the Recently Completed Expeditions Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These expeditions should be removed from the Scheduled Expeditions Excel file:  ['376']\n"
     ]
    }
   ],
   "source": [
    "# remove expeditions from Scheduled Expeditions Excel file (to be moved to Recently Completed Expeditions)\n",
    "\n",
    "# prepare files for recently completed expeditions\n",
    "old_excel_file = 'RecentlyCompletedExpeditions_May2018.xlsx'\n",
    "new_excel_file = 'RecentlyCompletedExpeditions_September2018.xlsx'\n",
    "\n",
    "# copy contents of old Excel file to new one for updating\n",
    "shutil.copy(old_excel_file, new_excel_file)\n",
    "\n",
    "print('These expeditions should be removed from the Scheduled Expeditions Excel file: ',rmfromxl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recently Completed Expeditions Excel file\n",
    "\n",
    "The bottom table on the [Expeditions Schedule page](https://www.iodp.org/expeditions/expeditions-schedule) shows expeditions that have been scheduled and completed. The actual drilling sites for these expeditions should be listed in their respective Scientific Prospectus documents.\n",
    "\n",
    "RecentlyCompletedExpeditions_MonthYear.xlsx contains the following data:  \n",
    "**Site Name / Latitude / Longitude / Name / Schedule / Icon / IconColor / IconScale / LabelScale / AppendDataColumnsToDescription / Description / Original Proposal / Drilling Platform / Co-chief Scientists / web info **\n",
    "\n",
    "Recently completed expeditions may not have been added to the Drilled Holes KML file on [iodp.org](https://www.iodp.org/resources/maps-and-kml-tools). If this is the case (i.e., JRSO, ESO, and CDEX have not responded to our request to update the drilled holes database), we need to add the data to the Recently Completed Expeditions Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# move expeditions that have been scheduled and completed to the Recently Completed Expeditions file\n",
    "\n",
    "# this was done manually as the last part of the previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Open the Drilled Holes KML file to check the most recent expeditions included. Remove those expeditions from the Excel file.\n",
    "\n",
    "Check the Excel files carefully before running the KML conversion code.\n",
    "\n",
    "Now you're done!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
